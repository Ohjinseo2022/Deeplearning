{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, LeakyReLU, UpSampling2D, Conv2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성자 모델을 만듭니다.\n",
    "generator = Sequential()\n",
    "generator.add(Dense(128*7*7, input_dim=100, activation=LeakyReLU(0.2)))\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(Reshape((7,7,128)))\n",
    "generator.add(UpSampling2D())\n",
    "generator.add(Conv2D(64, kernel_size=5,padding='same'))\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(Activation(LeakyReLU(0.2)))\n",
    "generator.add(UpSampling2D())\n",
    "generator.add(Conv2D(1,kernel_size=5, padding='same',activation='tanh'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#판별자 모델을 만듭니다.\n",
    "\n",
    "discriminator =Sequential()\n",
    "discriminator.add(Conv2D(64,kernel_size=5, strides=2, input_shape=(28,28,1),padding='same'))\n",
    "discriminator.add(Activation(LeakyReLU(0.2)))\n",
    "discriminator.add(Dropout(0.3))\n",
    "discriminator.add(Flatten())\n",
    "discriminator.add(Dense(1,activation='sigmoid'))\n",
    "discriminator.compile(loss='binary_crossentropy',optimizer='adam')\n",
    "discriminator.trainble=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100)]             0         \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, 28, 28, 1)         865281    \n",
      "                                                                 \n",
      " sequential_2 (Sequential)   (None, 1)                 14209     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 879,490\n",
      "Trainable params: 866,818\n",
      "Non-trainable params: 12,672\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#생성자와 판별자 모뎅을 연결시키는 gan모델을 만듭니다.\n",
    "\n",
    "ginput = Input(shape=(100,)) #생성자에 집어넣을 거 생성 ?\n",
    "dis_output =discriminator(generator(ginput)) #생성자의 실행결과를 판별자에 집어넣어 실행하고 결과값을 dis_output 저장 \n",
    "gan = Model(ginput,dis_output) # 새로운 gen 모델 생성 ! \n",
    "gan.compile(loss='binary_crossentropy',optimizer ='adam') \n",
    "gan.summary() # 구조확인을 위해 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#신경망을 실행시키는 함수를 만듭니다.\n",
    "def gan_train(epoch,batch_size, saving_interval):\n",
    "  \n",
    "# MNIST 데이터 불러오기\n",
    "    # 앞서 불러온 MNIST를 다시 이용합니다. 테스트 과정은 필요 없고\n",
    "    # 이미지만 사용할 것이기 때문에 X_train만 호출합니다.\n",
    "  (X_train, _),(_,_) = mnist.load_data()\n",
    "  X_train = X_train.reshape(X_train.shape[0],28,28,1).astype('float32')\n",
    "\n",
    "  #127.5를 뺀 후 127.5 로 나누어서 -1~1 사이의 값으로 바꿉니다.\n",
    "  X_train = (X_train - 127.5)/127.5\n",
    "  true = np.ones((batch_size,1))\n",
    "  fake = np.zeros((batch_size,1))\n",
    "\n",
    "  for i in range(epoch):\n",
    "    #실제 테이터를 판별자에 입력하는 부분입니다.\n",
    "    idx = np.random.randint(0, X_train.shape[0],batch_size)\n",
    "    imgs = X_train[idx]\n",
    "    d_loss_real = discriminator.train_on_batch(imgs,true)\n",
    "    #가상 이미지를 판별자에 입력하는 부분입니다.\n",
    "    noise = np.random.normal(0,1,(batch_size,100))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "    d_loss_fake = discriminator.train_on_batch(gen_imgs,fake)\n",
    "    #판별자와 생성자의 오차를 계산합니다.\n",
    "    d_loss= 0.5 *np.add(d_loss_real,d_loss_fake)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, _),(_,_) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a077222d77dfe082b8f1dd562ad70e458ac2ab76993a0b248ab0476e32e9e8dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
